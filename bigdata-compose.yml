version: '3.7'

networks:
  hadoop_net2:
    driver: bridge

services:
  namenode:
    container_name: namenode_container
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-namenode
    hostname: namenode
    environment:
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      CLUSTER_NAME: hadoop-cluster
      TZ: America/Mexico_City
    networks:
      - hadoop_net2
    volumes:
      - ./docker/compose/configs:/opt/hadoop/etc/hadoop:ro
      - hadoop_namenode:/hadoop/dfs/name
    ports:
      - "9870:9870"
      - "9000:9000"
      - "8020:8020"
    command: >
      bash -c "
      if [ ! -d /hadoop/dfs/name/current ]; then
        echo 'Formateando NameNode por primera vez...';
        hdfs namenode -format;
      fi;
      exec hdfs namenode"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9870/jmx?qry=Hadoop:service=NameNode,name=NameNodeStatus | grep -q 'active'"]
      interval: 10s
      timeout: 5s
      retries: 20
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1GB

  datanode:
    container_name: datanode_container
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-datanode
    hostname: datanode
    environment:
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      CLUSTER_NAME: hadoop-cluster
      TZ: America/Mexico_City
    networks:
      - hadoop_net2
    volumes:
      - ./docker/compose/configs:/opt/hadoop/etc/hadoop:ro
      - hadoop_datanode:/hadoop/dfs/data
    #PRUEBA
    ports:
      - "9864:9864"
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1GB
    command: >
      bash -c "
      while ! curl -sf http://namenode:9870/ >/dev/null; do
        echo 'Esperando a NameNode...';
        sleep 5;
      done;
      exec hdfs datanode"
    restart: unless-stopped
    depends_on:
      namenode:
        condition: service_healthy

  resourcemanager:
    container_name: resourcemanager_container
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-resourcemanager
    hostname: resourcemanager
    environment:
      SKIP_CONF_GENERATION: "true"
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
      CLUSTER_NAME: hadoop-cluster
      TZ: America/Mexico_City
    networks:
        - hadoop_net2
    entrypoint: ["bash", "-c", "exec yarn resourcemanager"]  # ðŸ‘ˆ Anula el entrypoint original
    volumes:
      - ./docker/compose/configs:/opt/hadoop/etc/hadoop:ro
      - hadoop_yarn_logs:/hadoop/yarn/logs
    ports:
      - "8088:8088"  # Web UI
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://resourcemanager:8088/ws/v1/cluster/info || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 20
    depends_on:
      - namenode
      - datanode
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2GB

  nodemanager:
    container_name: nodemanager_container
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-resourcemanager
    hostname: nodemanager
    environment:
      SKIP_CONF_GENERATION: "true" #Verificar
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
      CLUSTER_NAME: hadoop-cluster
      TZ: America/Mexico_City
    networks:
      - hadoop_net2
    entrypoint: ["bash", "-c", "exec yarn nodemanager"]
    volumes:
      - ./docker/compose/configs:/opt/hadoop/etc/hadoop:ro
      - hadoop_yarn_logs:/hadoop/yarn/logs
    ports:
      - "8042:8042"
    depends_on:
      - resourcemanager
    deploy:
      resources:
        limits:
          cpus: '6'
          memory: 12GB

  spark:
    container_name: spark_container
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-spark
    hostname: spark
    environment:
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
      - HADOOP_CONF_DIR=/opt/bitnami/spark/conf
      - YARN_CONF_DIR=/opt/bitnami/spark/conf
      - SPARK_MASTER=yarn
      - SPARK_SUBMIT_OPTIONS="--conf spark.jars.ivy=/tmp/.ivy2"
      - TZ=America/Mexico_City
    networks:
      - hadoop_net2
    volumes:
      - ./docker/compose/configs:/opt/bitnami/spark/conf:rw
      - ~/bigdata_platform/scripts:/opt/scripts
      - ~/bigdata_platform/jars:/opt/jars
    ports:
      - "4040:4040"
      - "7077:7077"
    healthcheck:
      test: ["CMD-SHELL", "netstat -tuln | grep 4040 || exit 1"]
      interval: 10s
      timeout: 2s
      retries: 10
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4GB
    command: >
      bash -c "
      until ping -c1 resourcemanager &>/dev/null; do
        echo 'Esperando a ResourceManager...';
        sleep 5;
      done;

      /opt/bitnami/spark/sbin/start-master.sh &&
      /opt/bitnami/spark/sbin/start-worker.sh spark://spark:7077 &&

      echo 'Configuraciones terminadas';
      tail -f /dev/null"

  jupyter-scala:
    hostname: jupyter
    container_name: jupyter-scala
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-jupyter
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ~/.ivy2:/home/jovyan/.ivy2
      - ~/bigdata_platform/scripts:/home/jovyan/scripts
    environment:
      - SPARK_MASTER=yarn://resourcemanager:8032
      - TZ=America/Mexico_City
    depends_on:
      - spark
    networks:
      - hadoop_net2

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - '2181:2181'
    environment:
      TZ: America/Mexico_City
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      start_period: 10s
      retries: 20
      interval: 10s
    networks:
      - hadoop_net2

  broker-kafka:
    image: confluentinc/cp-kafka:7.4.0    
    hostname: broker-kafka
    container_name: broker-kafka
    ports:
      - '29092:29092'
      - '9092:9092'
      - '9101:9101'
    environment:
      
      KAFKA_HEAP_OPTS: "-Xms2g -Xmx4g -XX:MaxDirectMemorySize=3g"
      KAFKA_JVM_PERFORMANCE_OPTS: >-
        -server
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=20
        -XX:InitiatingHeapOccupancyPercent=35
        -XX:+ExplicitGCInvokesConcurrent
        -Djava.awt.headless=true

      
      KAFKA_MESSAGE_MAX_BYTES: "104857600"        
      KAFKA_REPLICA_FETCH_MAX_BYTES: "104857600"  
      KAFKA_FETCH_MAX_BYTES: "104857600"          
      KAFKA_SOCKET_REQUEST_MAX_BYTES: "104857600" 
      
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: "2097152"
      KAFKA_SOCKET_SEND_BUFFER_BYTES: "2097152"   
      
      KAFKA_NUM_NETWORK_THREADS: "6"
      KAFKA_NUM_IO_THREADS: "12"
      KAFKA_NUM_REPLICA_FETCHERS: "1"
      
      KAFKA_BROKER_ID: "1"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_NUM_PARTITIONS: "3"
      KAFKA_DEFAULT_REPLICATION_FACTOR: "1"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker-kafka:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      ALLOW_PLAINTEXT_LISTENER: "yes"
      
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_BYTES: "53687091200"  
      KAFKA_LOG_SEGMENT_BYTES: "1073741824"     
      KAFKA_LOG_RETENTION_HOURS: "168"          
      KAFKA_LOG_CLEANUP_POLICY: "delete"

      KAFKA_JMX_PORT: "9101"
      KAFKA_JMX_HOSTNAME: "localhost"
      TZ: "America/Mexico_City"
    healthcheck:
      test: nc -z broker-kafka 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - hadoop_net2
    deploy:
      resources:
        limits:
          memory: 6g
          cpus: '2'
  control-center:
    image: confluentinc/cp-enterprise-control-center:7.4.0
    hostname: control-center
    container_name: control-center
    depends_on:
      broker:
        condition: service_healthy
    ports:
      - "9021:9021"
    environment:
      TZ: America/Mexico_City
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONFLIENT_METRICS_ENABLE: 'false'
      PORT: 9021
    networks:
      - hadoop_net2
    command: >
      bash -c "
      while ! curl -sf http://broker:9092/ >/dev/null; do
        echo 'Esperando a broker...';
        sleep 5;
      done;"
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://control-center:9021/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  debezium:
    image: debezium/connect:2.5
    container_name: debezium
    hostname: debezium
    depends_on:
      postgres:
        condition: service_healthy
      broker:
        condition: service_healthy
    ports:
      - '8093:8083'
    environment:
      TZ: America/Mexico_City
      BOOTSTRAP_SERVERS: broker:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: debezium
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      STATUS_STORAGE_TOPIC: connect_statuses
      OFFSET_STORAGE_TOPIC: connect_offsets
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      ENABLE_DEBEZIUM_SCRIPTING: 'true'
    healthcheck:
      test:
        [ 'CMD', 'curl', '--silent', '--fail', '-X', 'GET', 'http://debezium:8083/connectors', ]
      start_period: 10s
      interval: 10s
      timeout: 5s
      retries: 5    
    networks:
      - hadoop_net2

  debezium-ui:
    image: debezium/debezium-ui:latest
    container_name: debezium-ui
    hostname: debezium-ui
    depends_on:
      debezium:
        condition: service_healthy
    ports:
      - '8080:8080'
    environment:
      TZ: America/Mexico_City
      KAFKA_CONNECT_URIS: http://debezium:8083
    networks:
      - hadoop_net2

  postgres:
    image: postgres:latest
    container_name: postgres
    hostname: postgres
    ports:
      - '5432:5432'
    environment:
      TZ: America/Mexico_City
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: financial_db
    command: [ 'postgres', '-c', 'wal_level=logical' ]
    healthcheck:
      test: [ 'CMD', 'psql', '-U', 'postgres', '-c', 'SELECT 1' ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - hadoop_net2

#HIVE JAIME  

  hive-postgres:
    image: postgres:15-alpine  # Oficial + ligero
    container_name: hive-postgres
    hostname: hive-postgres
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive_user -d metastore"]
      interval: 5s
      timeout: 5s
      retries: 5
    environment:
      - TZ=America/Mexico_City
      - POSTGRES_USER=hive_user
      - POSTGRES_PASSWORD=mypassword
      - POSTGRES_DB=metastore
      - POSTGRES_HOST_AUTH_METHOD=trust  # Â¡Clave!
    volumes:
      - hive_metastore_data:/var/lib/postgresql/data
    ports:
      - "55432:5432"  # Buen puerto custom
    networks:
      - hadoop_net2

  hive-metastore:
    container_name: hive-metastore
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-hive-metastore
    hostname: hive-metastore
    env_file:
      - ./docker/compose/configs/hadoop-hive.env
    environment:
      TZ: America/Mexico_City
      SERVICE_PRECONDITION: "namenode:9000 hive-postgres:5432"  
      DB_TYPE: postgres
      DB_URI: jdbc:postgresql://hive-postgres:5432/metastore
      DB_USER: hive_user
      DB_PASS: mypassword
    ports:
      - "9083:9083"
    restart: unless-stopped
    depends_on:
      hive-postgres:
        condition: service_started
      namenode:
        condition: service_started
    networks:
      - hadoop_net2
  
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    env_file:
      - ./docker/compose/configs/hadoop-hive.env
    depends_on:
      hive-metastore:
        condition: service_started
    environment:
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
    command: /opt/hive/bin/hiveserver2
    restart: unless-stopped
    networks:
      - hadoop_net2


  mysql:
    image: mysql:8.0
    container_name: mysql-container
    hostname: mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
    volumes:
      - ./mysql_data:/var/lib/mysql
    command: --binlog-format=ROW
    networks:
      - hadoop_net2

  jobmanager:
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-flink
    container_name: flink-jobmanager
    hostname: jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    volumes:
      - ~/bigdata_platform/jars:/opt/flink/usrlib
    networks:
      - hadoop_net2

  taskmanager:
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-flink
    container_name: flink-taskmanager
    hostname: taskmanager
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    networks:
      - hadoop_net2
    
  scala-compiler:
    build:
      context: .
      dockerfile: ./docker/files/Dockerfile-scala
    container_name: scala-compiler
    volumes:
      - ~/bigdata_platform/scripts:/opt/scripts
      - ~/bigdata_platform/jars:/opt/jars
    command: sbt assembly
    networks:
      - hadoop_net2

  
volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_yarn_logs:  
  spark_logs:
  hive_metastore_data:
